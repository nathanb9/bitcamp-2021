{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of drone_data_load.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy3XGGxpAYay",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "7e1e430c-fa56-4314-a19a-d05639505b8d"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "​\n",
        "# Store in variables: (X_train, Y_train)\n",
        "x = loadmat(\"ml_features.mat\")\n",
        "X_train = x['ml_features']\n",
        "X_train = np.asarray(X_train)\n",
        "​\n",
        "y = loadmat(\"ground_truth_angles.mat\")   \n",
        "Y_train = y['ground_truth_angles']\n",
        "Y_train = np.asarray(Y_train)\n",
        "​\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "​\n",
        "# 381 features\n",
        "# 14440 data points\n",
        "​\n",
        "# index id where angle = 0 and 90\n",
        "id_0 = Y_train==0\n",
        "id_0 = id_0[:,0]\n",
        "id_90 = Y_train==90\n",
        "id_90 = id_90[:,0]\n",
        "​\n",
        "# features where angle = 0 and 90\n",
        "feature_0 = X_train[0,:,0,id_0]\n",
        "feature_90 = X_train[0,:,0,id_90]\n",
        "​\n",
        "# plotting the features\n",
        "plt.figure()\n",
        "plt.plot(feature_0[1,:])\n",
        "plt.plot(feature_90[1,:])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-338fcaa4ffca>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    ​\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GpkvgSF8VeB"
      },
      "source": [
        "#I made new varialbes in a shape that more closely related a tutorial I was following\n",
        "x_t = np.empty(shape=(11552,381),dtype='float') #x_t for 'x training data'\n",
        "y_t = np.empty(shape=(11552,1),dtype='float') \n",
        "\n",
        "x_v = np.empty(shape=(2888,381),dtype='float') #x_v for 'x valitdating data'\n",
        "y_v = np.empty(shape=(2888,1),dtype='float')\n",
        "\n",
        "x = np.linspace(0,14439, 14440, dtype=int)\n",
        "count = int(0)\n",
        "for i in x:\n",
        "    if i%5 == 0:\n",
        "        b = int(i/5)\n",
        "        x_v[b,:] = X_train[:,:,:,i].flatten()\n",
        "        y_v[b] = Y_train[i]\n",
        "        count = count + 1\n",
        "    else:\n",
        "        x_t[i-count,:] = X_train[:,:,:,i].flatten()\n",
        "        y_t[i-count] = Y_train[i]\n",
        "y_v = y_v.flatten()\n",
        "y_t = y_t.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BdKEEdL--k-"
      },
      "source": [
        "# These were just some functions used to make the data scale from 0 to 1\n",
        "# and do other necassary things i can't explain why\n",
        "def preprocess(x, y):\n",
        "  x = tf.cast(x, tf.float32) / 3.1415920147494263\n",
        "  y = tf.cast(y, tf.int64)\n",
        "\n",
        "  return x, y\n",
        "\n",
        "def create_dataset(xs, ys, n_classes=360):\n",
        "  ys = tf.one_hot(ys, depth=n_classes)\n",
        "  return tf.data.Dataset.from_tensor_slices((xs, ys)) \\\n",
        "    .map(preprocess) \\\n",
        "    .shuffle(len(ys)) \\\n",
        "    .batch(128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9dghgoJ_h2_"
      },
      "source": [
        "train_dataset = create_dataset(x_t, y_t)\n",
        "val_dataset = create_dataset(x_v, y_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP0ZS6ts_k1Q"
      },
      "source": [
        "#making a model with 4 layers\n",
        "#starts with 381 input values fot the 381 features\n",
        "#does some random stuff idk\n",
        "#ends with a guess of which 360 angles\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(units=381, input_shape=(381,), activation='elu'),\n",
        "    keras.layers.Dense(units=300, activation='sigmoid'),\n",
        "    keras.layers.Dense(units=200, activation='relu'),\n",
        "    keras.layers.Dense(units=360, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdePJnlUAI9Z"
      },
      "source": [
        "#Here the model is being trained with out training dataset and tested with our validation dataset\n",
        "model.compile(optimizer='adam', \n",
        "              loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset.repeat(), \n",
        "    epochs=10, \n",
        "    steps_per_epoch=500,\n",
        "    validation_data=val_dataset.repeat(), \n",
        "    validation_steps=3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCa8gdQSAlvo"
      },
      "source": [
        "# This is all kinda unrelated to the stuff above but its a method I found online\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(x_t, y_t)\n",
        "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
        "     .format(gnb.score(x_t, y_t)))\n",
        "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
        "     .format(gnb.score(x_v, y_v)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}